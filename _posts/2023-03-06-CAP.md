---
layout: post
title:  "CAP"
date:   2023-03-06 17:19:52 +0800
categories: cap "system design"
---

### 1. [CAP theorem](https://twitter.com/alexxubyte/status/1575150633358802944)

> The CAP theorem is one of the most famous terms in computer science. Let’s examine what it is and why it can be confusing.

![CAP theorem](https://pbs.twimg.com/media/FdwPJtlUoAAQMEd?format=jpg&name=4096x4096)

CAP theorem states that a distributed system can't provide more than two of these three guarantees simultaneously.
- 𝐂𝐨𝐧𝐬𝐢𝐬𝐭𝐞𝐧𝐜𝐲: consistency means all clients see the same data at the same time no matter which node they connect to.
- 𝐀𝐯𝐚𝐢𝐥𝐚𝐛𝐢𝐥𝐢𝐭𝐲: availability means any client which requests data gets a response even if some of the nodes are down.
- 𝐏𝐚𝐫𝐭𝐢𝐭𝐢𝐨𝐧 𝐓𝐨𝐥𝐞𝐫𝐚𝐧𝐜𝐞: a partition indicates a communication break between two nodes. Partition tolerance means the system continues to operate despite network partitions.

The “2 of 3” formulation can be useful, 𝐛𝐮𝐭 𝐭𝐡𝐢𝐬 𝐬𝐢𝐦𝐩𝐥𝐢𝐟𝐢𝐜𝐚𝐭𝐢𝐨𝐧 𝐜𝐨𝐮𝐥𝐝 𝐛𝐞 𝐦𝐢𝐬𝐥𝐞𝐚𝐝𝐢𝐧𝐠.
1. Picking a database is not easy. Justifying our choice purely based on the CAP theorem is not enough. e.g., companies don't choose Cassandra for chat applications simply because it is an AP system. There is a list of good characteristics that make it a desirable option.
2. “CAP prohibits only a tiny part of the design space: perfect availability and consistency in the presence of partitions, which are rare”. Quoted from the paper: CAP Twelve Years Later: How the “Rules” Have Changed.
3. The theorem is about 100% availability and consistency. A more realistic discussion would be the trade-offs between latency and consistency when there is no network partition. See PACELC theorem for more details.

𝐈𝐬 𝐭𝐡𝐞 𝐂𝐀𝐏 𝐭𝐡𝐞𝐨𝐫𝐞𝐦 𝐚𝐜𝐭𝐮𝐚𝐥𝐥𝐲 𝐮𝐬𝐞𝐟𝐮𝐥?
- I think it is still useful as it opens our minds to a set of tradeoff discussion, but it is only part of the story. We need to dig deeper when picking the right database

<br/>

---

<br/>

### 2. [High Availability](https://twitter.com/alexxubyte/status/1537100597110792192)

> In the famous CAP theorem by computer scientist Eric Brewer, Availability means ​​all (non-failing) nodes are available for queries in a distributed system.
>
> Usually, we design a system for high availability. For example, when we say the design target is 4-9’s, it means the services should be up 99.99% of the time. This also means the services can only be down for 52.5 minutes per year.
>
> Note that availability only guarantees that we will receive a response; it doesn’t guarantee the data is the most up-to-date.
>
> The diagram below shows how we can turn a single-node “Product Inventory” into a double-node architecture with high availability.

![High Availability](https://pbs.twimg.com/media/FVTg2FEUEAIZS7-?format=jpg&name=4096x4096)

1. ***Primary-Backup***: the backup node is just a stand-by, and the data is replicated from primary to backup. When the primary fails, we need to manually switch to the backup node.
> The backup node might be a waste of hardware resources.

2. ***Primary-Secondary***: this architecture looks similar to primary-backup architecture, but the secondary node can take read requests to balance the reading load.
> Due to latency when replicating data from primary to secondary, the data read from the secondary may be inconsistent with the primary.

3. ***Primary-Primary***: both nodes act as primary nodes, both nodes can handle read/write operations, and the data is replicated between the two nodes. This type of architecture increases the throughput, but it has limited use cases.
> For example, if both nodes need to update the same product, the final state might be unpredictable. Use this architecture with caution!
> 
> If we deploy the node on Amazon EC2, which has 90% availability, the double-node architecture will increase availability from 90% to 99%.