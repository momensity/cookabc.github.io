---
layout: post
title:  "HTTP"
date:   2023-02-27 19:24:26 +0800
categories: http
---

### 1. [HTTP 1.0 -> HTTP 1.1 -> HTTP 2.0 -> HTTP 3.0 (QUIC)](https://twitter.com/alexxubyte/status/1509200416403189765)

> What problem does each generation of HTTP solve?
>
> The diagram below illustrates the key features.

![HTTP versions](https://pbs.twimg.com/media/FPG-V1jVgAMHO7m?format=jpg&name=medium)

- HTTP 1.0 was finalized and fully documented in 1996. Every request to the same server requires a separate TCP connection.

- HTTP 1.1 was published in 1997. A TCP connection can be left open for reuse (persistent connection), but it doesn’t solve the HOL (head-of-line) blocking issue.
    > HOL blocking - when the number of allowed parallel requests in the browser is used up, subsequent requests need to wait for the former ones to complete.

- HTTP 2.0 was published in 2015. It addresses HOL issue through request multiplexing, which eliminates HOL blocking at the application layer, but HOL still exists at the transport (TCP) layer.
    > As you can see in the diagram, HTTP 2.0 introduced the concept of HTTP “streams”: an abstraction that allows multiplexing different HTTP exchanges onto the same TCP connection. Each stream doesn’t need to be sent in order.

- HTTP 3.0 first draft was published in 2020. It is the proposed successor to HTTP 2.0. It uses QUIC instead of TCP for the underlying transport protocol, thus removing HOL blocking in the transport layer.
    > QUIC is based on UDP. It introduces streams as first-class citizens at the transport layer. QUIC streams share the same QUIC connection, so no additional handshakes and slow starts are required to create new ones.
    > 
    > But QUIC streams are delivered independently such that in most cases packet loss affecting one stream doesn't affect others.


<br/>

---

<br/>

### 2. [How does HTTPS work?](https://twitter.com/alexxubyte/status/1521883407864590337)

> Hypertext Transfer Protocol Secure (HTTPS) is an extension of the Hypertext Transfer Protocol (HTTP) 
> HTTPS transmits encrypted data using Transport Layer Security (TLS) 
> If the data is hijacked online, all the hijacker gets is binary code.

![How does HTTPS work](https://pbs.twimg.com/media/FR7Qf7LVgAAl6Vr?format=jpg&name=medium)

**How is the data encrypted and decrypted?**

- Step 1 - The client (browser) and the server establish a TCP connection.
- Step 2 - The client sends a “client hello” to the server. The message contains a set of necessary encryption algorithms and the latest TLS version it can support. The server responds with a “server hello” so the browser knows whether it can support the algorithms and TLS version. The server then sends the SSL certificate to the client. The certificate contains the public key, host name, expiry dates, etc. The client validates the certificate.
- Step 3 - After validating the SSL certificate, the client generates a session key and encrypts it using the public key. The server receives the encrypted session key and decrypts it with the private key.
- Step 4 - Now that both the client and the server hold the same session key (symmetric encryption), the encrypted data is transmitted in a secure bi-directional channel.

**Why does HTTPS switch to symmetric encryption during data transmission? There are two main reasons:**

1. Security: The asymmetric encryption goes only one way. This means that if the server tries to send the encrypted data back to the client, anyone can decrypt the data using the public key.
2. Server resources: The asymmetric encryption adds quite a lot of mathematical overhead. It is not suitable for data transmissions in long sessions.

<br/>

---

<br/>

### 3. [Is HTTPS reliable?](https://twitter.com/alexxubyte/status/1562103641057607685)

> If HTTPS is safe, how can tools like Fiddler capture network packets sent via HTTPS?
>
> The diagram below shows a scenario where a malicious intermediate hijacks the packets.

![Is HTTPS reliable](https://pbs.twimg.com/media/Fa20-tQVQAkQMtG?format=jpg&name=medium)

- Step 1 - The client requests to establish a TCP connection with the server. The request is maliciously routed to an intermediate server, instead of the real backend server. Then, a TCP connection is established between the client and the intermediate server.
- Step 2 - The intermediate server establishes a TCP connection with the actual server.
- Step 3 - The intermediate server sends the SSL certificate to the client. The certificate contains the public key, hostname, expiry dates, etc. The client validates the certificate.
- Step 4 - The legitimate server sends its certificate to the intermediate server. The intermediate server validates the certificate.
- Step 5 - The client generates a session key and encrypts it using the public key from the intermediate server. The intermediate server receives the encrypted session key and decrypts it with the private key.
- Step 6 - The intermediate server encrypts the session key using the public key from the actual server and then sends it there. The legitimate server decrypts the session key with the private key.
- Steps 7 and 8 - Now, the client and the server can communicate using the session key (symmetric encryption.) The encrypted data is transmitted in a secure bi-directional channel. The intermediate server can always decrypt the data.

**Now let’s answer the questions we started with:**
1. HTTPS is reliable, but the client should not accept a malicious certificate from an untrusted third-party server.
2. Fiddler can decrypt the data because its certificate is accepted and trusted by the browser.

<br/>

---

<br/>

### 4. [How do we properly deal with HTTP errors?](https://twitter.com/alexxubyte/status/1533839240806551552)

> How do we properly deal with HTTP errors on the browser side?
> And how do you handle them correctly on the server side when the client side is at fault?

![deal with HTTP errors](https://pbs.twimg.com/media/FUlKqMZUsAEhAfx?format=jpg&name=medium)

**From the browser's point of view,** the easiest thing to do is to try again and hope the error just goes away. This is a good idea in a distributed network, but we also have to be very careful not to make things worse. Here’s two general rules:
1. For ***4XX*** http error code, do not retry.
2. For ***5XX*** http error code, try again carefully.

**So which things should we do carefully in the browser?** We definitely should not overwhelm the server with retried requests. An algorithm named exponential backoff might be able to help. It controls two things:
1. The latency between two retries. The latency will increase exponentially.
2. The number of retries is usually capped.


**Will all browsers handle their retry logic in a graceful way?** Most likely not. So the server has to take care of its own safety. A common way to control the flow of HTTP requests is to set up a flow control gateway in front of the server. This provides two useful tools:
1. ***Rate limiter***, which limits how often a request can be made. It has two slightly different choices: `the token bucket` and `the leaky bucket`.
2. ***Circuit breaker***. This will stop the HTTP flow immediately when the error threshold is exceeded. After a set amount of time, it will only let a limited amount of HTTP traffic through. If everything works well, it will slowly let all HTTP traffic through.
